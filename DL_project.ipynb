{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0DLlaIbqHcNcXoh4QiEMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoroman1/DL_project/blob/main/DL_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJYPASMc94rC"
      },
      "outputs": [],
      "source": [
        "# connect to your drive with the dataset folder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour'\n",
        "images_dir = '/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/imagesTr'\n",
        "labels_dir = '/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/labelsTr'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset tar extraction ONLY IF NEEDED\n",
        "\n",
        "import tarfile\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Paths (modify as needed)\n",
        "tar_path = '/content/drive/MyDrive/Task01_BrainTumour.tar'\n",
        "destination_path = '/content/drive/MyDrive/Task01_BrainTumour'\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Open and extract with progress bar\n",
        "with tarfile.open(tar_path) as tar:\n",
        "    members = tar.getmembers()\n",
        "    print(f\"Extracting {len(members)} files to: {destination_path}\")\n",
        "    for member in tqdm(members, desc=\"Extracting\", unit=\"file\"):\n",
        "        tar.extract(member, path=destination_path)\n",
        "\n",
        "print(\"Extraction completed.\")\n"
      ],
      "metadata": {
        "id": "woXdVyyO-bfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO:\n",
        "\n",
        ". normalization fatta bene\n",
        "\n",
        ". crop and back to original padding (capire se ha senso)\n",
        "\n",
        ". fare dice loss bene e vedere come combinarla a cross entropy bene\n",
        "\n",
        ". sistemare tutti i codici ordinati e con variabili ben nominate"
      ],
      "metadata": {
        "id": "9TENrkHjDU6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "\n",
        "image_dir = \"/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/imagesTr\"\n",
        "label_dir = \"/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/labelsTr\"\n",
        "\n",
        "# Filter out hidden/system files like ._BRATS_001.nii.gz\n",
        "def is_valid_nifti(fname):\n",
        "    return fname.endswith(\".nii.gz\") and not fname.startswith(\"._\")\n",
        "\n",
        "# Get sorted lists of image and label paths\n",
        "image_paths = sorted([\n",
        "    os.path.join(image_dir, fname)\n",
        "    for fname in os.listdir(image_dir)\n",
        "    if is_valid_nifti(fname)\n",
        "])\n",
        "\n",
        "label_paths = sorted([\n",
        "    os.path.join(label_dir, fname)\n",
        "    for fname in os.listdir(label_dir)\n",
        "    if is_valid_nifti(fname)\n",
        "])\n",
        "\n",
        "# Sanity check: print number of samples\n",
        "print(\"Number of samples:\", len(image_paths))\n",
        "\n",
        "# Show dimensions and sample names for the first 10\n",
        "for img_path, lbl_path in zip(image_paths[:10], label_paths[:10]):\n",
        "    img = nib.load(img_path)\n",
        "    lbl = nib.load(lbl_path)\n",
        "\n",
        "    img_data = img.get_fdata()\n",
        "    lbl_data = lbl.get_fdata()\n",
        "\n",
        "    print(f\"\\nImage: {os.path.basename(img_path)} - Shape: {img_data.shape}\")\n",
        "    print(f\"Label: {os.path.basename(lbl_path)} - Shape: {lbl_data.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vdo0C1HwmsqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_dir = \"/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/imagesTr\"\n",
        "label_dir = \"/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/labelsTr\"\n",
        "\n",
        "def is_valid_nifti(fname):\n",
        "    return fname.endswith(\".nii.gz\") and not fname.startswith(\"._\")\n",
        "\n",
        "image_paths = sorted([\n",
        "    os.path.join(image_dir, fname)\n",
        "    for fname in os.listdir(image_dir)\n",
        "    if is_valid_nifti(fname)\n",
        "])\n",
        "\n",
        "label_paths = sorted([\n",
        "    os.path.join(label_dir, fname)\n",
        "    for fname in os.listdir(label_dir)\n",
        "    if is_valid_nifti(fname)\n",
        "])\n",
        "\n",
        "# Load first image and label\n",
        "img = nib.load(image_paths[0]).get_fdata()\n",
        "lbl = nib.load(label_paths[0]).get_fdata()\n",
        "\n",
        "num_slices = img.shape[2]\n",
        "first_10 = list(range(50, 60))\n",
        "last_10 = list(range(70, 80))\n",
        "slices_to_show = first_10 + last_10\n",
        "\n",
        "modalities = ['T1', 'T1c', 'T2', 'FLAIR']\n",
        "\n",
        "for slice_idx in slices_to_show:\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
        "    fig.suptitle(f\"Slice {slice_idx}\")\n",
        "\n",
        "    for ch in range(4):\n",
        "        slice_img = img[:, :, slice_idx, ch]\n",
        "        slice_img_norm = (slice_img - slice_img.min()) / (slice_img.max() - slice_img.min() + 1e-8)\n",
        "        axs[ch].imshow(slice_img_norm, cmap='gray')\n",
        "        axs[ch].set_title(modalities[ch])\n",
        "        axs[ch].axis('off')\n",
        "\n",
        "    # Show label mask as last image in the row\n",
        "    axs[4].imshow(lbl[:, :, slice_idx], cmap='nipy_spectral', vmin=0, vmax=4)\n",
        "    axs[4].set_title('Label')\n",
        "    axs[4].axis('off')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vhhshNSco5aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "label_dir = \"/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/labelsTr\"\n",
        "\n",
        "def is_valid_nifti(fname):\n",
        "    return fname.endswith(\".nii.gz\") and not fname.startswith(\"._\")\n",
        "\n",
        "label_paths = sorted([\n",
        "    os.path.join(label_dir, fname)\n",
        "    for fname in os.listdir(label_dir)\n",
        "    if is_valid_nifti(fname)\n",
        "])\n",
        "\n",
        "# Load first label mask\n",
        "label_img = nib.load(label_paths[0])\n",
        "label_data = label_img.get_fdata()\n",
        "\n",
        "# Print unique values and their counts\n",
        "unique_vals, counts = np.unique(label_data, return_counts=True)\n",
        "\n",
        "print(\"Unique label values and their counts:\")\n",
        "for val, count in zip(unique_vals, counts):\n",
        "    print(f\"Label {int(val)}: {count} voxels\")\n"
      ],
      "metadata": {
        "id": "G-Jagjh-q_dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hrusory1_vQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gjOWKd3J-Rmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJjs6fncrATg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Paths\n",
        "simple_test_images_dir = '/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/samples_imagesTr'\n",
        "simple_test_labels_dir = '/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/samples_labelsTr'\n",
        "\n",
        "# Create dirs if not exist\n",
        "os.makedirs(simple_test_images_dir, exist_ok=True)\n",
        "os.makedirs(simple_test_labels_dir, exist_ok=True)\n",
        "\n",
        "# Get first 25 files (excluding hidden/system files)\n",
        "images_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.nii.gz') and not f.startswith('._')])[:25]\n",
        "\n",
        "\n",
        "\n",
        "for f in images_files:\n",
        "    src_img = os.path.join(images_dir, f)\n",
        "    dst_img = os.path.join(simple_test_images_dir, f)\n",
        "    if not os.path.exists(dst_img):\n",
        "        shutil.copy(src_img, dst_img)\n",
        "    else:\n",
        "        print(f\"Image file {f} already exists, skipping.\")\n",
        "\n",
        "    src_label = os.path.join(labels_dir, f)\n",
        "    dst_label = os.path.join(simple_test_labels_dir, f)\n",
        "    if not os.path.exists(dst_label):\n",
        "        shutil.copy(src_label, dst_label)\n",
        "    else:\n",
        "        print(f\"Label file {f} already exists, skipping.\")\n"
      ],
      "metadata": {
        "id": "oKFHZICZegt1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "input_layer = layers.Input(shape=(240, 240, 4))  # 4 channels\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "output_layer = layers.Conv2D(4, (1, 1), activation='softmax')(x)  # softmax for multi-class\n",
        "\n",
        "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss=combined_loss, metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "QjgMbWlzh-1w"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class BrainTumor2DSliceGenerator(Sequence):\n",
        "    def __init__(self, image_dir, label_dir, batch_size=8, slice_step=1, shuffle=True):\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.slice_step = slice_step\n",
        "        # Filter out files starting with '._'\n",
        "        self.patient_ids = sorted([f.replace('.nii.gz', '') for f in os.listdir(image_dir) if not f.startswith('._')])\n",
        "        self.indexes = self._create_index_list()\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def _create_index_list(self):\n",
        "        index_list = []\n",
        "        for pid in self.patient_ids:\n",
        "            img_path = os.path.join(self.image_dir, pid + '.nii.gz')\n",
        "            img = nib.load(img_path).get_fdata()  # shape: H x W x D x C\n",
        "            for i in range(0, img.shape[2], self.slice_step):\n",
        "                index_list.append((pid, i))\n",
        "        return index_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.indexes) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_X = []\n",
        "        batch_y = []\n",
        "        for pid, slice_idx in batch_indexes:\n",
        "            img = nib.load(os.path.join(self.image_dir, pid + '.nii.gz')).get_fdata()\n",
        "            label = nib.load(os.path.join(self.label_dir, pid + '.nii.gz')).get_fdata()\n",
        "            img_slice = img[:, :, slice_idx, :]  # shape: H x W x C\n",
        "            label_slice = label[:, :, slice_idx]  # shape: H x W\n",
        "\n",
        "            # Normalize and cast\n",
        "            img_slice = (img_slice - np.mean(img_slice)) / (np.std(img_slice) + 1e-5)\n",
        "            batch_X.append(img_slice)\n",
        "            batch_y.append(label_slice)\n",
        "\n",
        "        return np.array(batch_X), np.array(batch_y).astype(np.int32)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "def dice_loss_per_class(y_true, y_pred, num_classes=4, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Computes Dice loss per class and averages over all classes.\n",
        "    Accepts sparse integer labels (y_true) and softmax outputs (y_pred).\n",
        "    \"\"\"\n",
        "    if len(y_true.shape) == 3:\n",
        "        y_true = tf.expand_dims(y_true, axis=-1)\n",
        "\n",
        "    y_true_one_hot = tf.one_hot(tf.cast(y_true[..., 0], tf.int32), depth=num_classes)\n",
        "\n",
        "    dice = 0\n",
        "    for c in range(num_classes):\n",
        "        y_true_c = y_true_one_hot[..., c]\n",
        "        y_pred_c = y_pred[..., c]\n",
        "        intersection = tf.reduce_sum(y_true_c * y_pred_c)\n",
        "        denominator = tf.reduce_sum(y_true_c) + tf.reduce_sum(y_pred_c)\n",
        "        dice += (2. * intersection + smooth) / (denominator + smooth)\n",
        "\n",
        "    return 1 - dice / num_classes\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    ce_loss = tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred)\n",
        "    dice = dice_loss_per_class(y_true, y_pred, num_classes=4)\n",
        "    return ce_loss + dice\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pD6fczirh-v2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_test_data_gen = BrainTumor2DSliceGenerator(\n",
        "    simple_test_images_dir,\n",
        "    simple_test_labels_dir,\n",
        "    batch_size=8,\n",
        "    slice_step=4,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "model.fit(simple_test_data_gen, epochs=3)\n"
      ],
      "metadata": {
        "id": "MQKhYqyTb-B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Define number of classes\n",
        "num_classes = 4\n",
        "\n",
        "# Define a discrete colormap with distinct colors (can customize colors)\n",
        "colors = ['black', 'green', 'yellow', 'red']  # one color per class, adjust as you like\n",
        "cmap = mcolors.ListedColormap(colors)\n",
        "\n",
        "# Define boundaries between classes for normalization\n",
        "bounds = list(range(num_classes + 1))  # [0,1,2,3,4]\n",
        "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "# Set paths\n",
        "\n",
        "test_volume_path = '/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/samples_imagesTr/BRATS_001.nii.gz'\n",
        "label_path       = '/content/drive/MyDrive/Task01_BrainTumour/Task01_BrainTumour/samples_labelsTr/BRATS_001.nii.gz'\n",
        "\n",
        "# Load volume & label\n",
        "\n",
        "img = nib.load(test_volume_path).get_fdata()   # shape: H x W x D x 4\n",
        "label = nib.load(label_path).get_fdata().astype(np.int32)  # shape: H x W x D\n",
        "\n",
        "\n",
        "# Customize range of slices\n",
        "\n",
        "start_slice = 45\n",
        "end_slice = 50\n",
        "\n",
        "\n",
        "# Predict and show\n",
        "\n",
        "for i in range(start_slice, end_slice):\n",
        "    # Extract the slice (H x W x 4)\n",
        "    img_slice = img[:, :, i, :]\n",
        "    label_slice = label[:, :, i]\n",
        "\n",
        "    # Preprocess (same as training)\n",
        "    img_slice_norm = (img_slice - np.mean(img_slice)) / (np.std(img_slice) + 1e-5)\n",
        "\n",
        "    # Add batch dimension\n",
        "    input_slice = np.expand_dims(img_slice_norm, axis=0)  # shape: 1 x H x W x 4\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(input_slice, verbose=0)\n",
        "    pred_class = np.argmax(pred[0], axis=-1)  # shape: H x W\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(img_slice[:, :, 0], cmap='gray')  # Show channel 0 (e.g., T1)\n",
        "    plt.title(f'Slice {i} - MRI (T1)')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(label_slice, cmap=cmap, norm=norm)\n",
        "    plt.title('Ground Truth')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(pred_class, cmap=cmap, norm=norm)\n",
        "    plt.title('Model Prediction')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "UZypDJdnuObW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_class = np.argmax(pred[0], axis=-1)  # shape: H x W\n",
        "unique, counts = np.unique(pred_class, return_counts=True)\n",
        "print(f\"Prediction class distribution (slice {i}):\")\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u}: {c} pixels\")\n",
        "\n",
        "# ampliare facendo codice che fa vedere proporzione label azzeccati su totale per ogni classe"
      ],
      "metadata": {
        "id": "QWbaSuD1u8La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_dir = '/content/drive/MyDrive/Task01_BrainTumour/models'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "model_path = os.path.join(save_dir, '2D_Unet_Dice_crossE_25samples_8batch_4step.keras')\n",
        "\n",
        "model.save(model_path)\n",
        "print(f\"Model saved to: {model_path}\")\n"
      ],
      "metadata": {
        "id": "zIUtuCid3Bff"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}